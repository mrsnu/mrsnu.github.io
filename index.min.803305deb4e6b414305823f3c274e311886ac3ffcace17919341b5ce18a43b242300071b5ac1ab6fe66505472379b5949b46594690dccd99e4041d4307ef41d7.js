var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/docs/prologue/",title:"Prologue",description:"Prologue Doks.",content:""}),e.add({id:1,href:"/docs/getting-started/",title:"Getting Started",description:"Getting Started",content:""}),e.add({id:2,href:"/docs/api/",title:"API",description:"API",content:""}),e.add({id:3,href:"/docs/prologue/introduction/",title:"Introduction",description:`Band is an efficient deep learning platform for mobile-cloud collaborative support for multiple DNNs. Band supports backend-agnostic coordination of DNN requests on heterogeneous processors in a mobile device to cloud server. Band is currently backed by following backend machine learning frameworks.
Tensorflow v2.9.2 \u0026hellip; Android ☑ iOS ☐ gRPC ☐ Band provides Java and C APIs, as well as an official plugin for Unreal Engine.
Tutorial # 👉 The Tutorial is intended for novice to intermediate users.`,content:`Band is an efficient deep learning platform for mobile-cloud collaborative support for multiple DNNs. Band supports backend-agnostic coordination of DNN requests on heterogeneous processors in a mobile device to cloud server. Band is currently backed by following backend machine learning frameworks.
Tensorflow v2.9.2 \u0026hellip; Android ☑ iOS ☐ gRPC ☐ Band provides Java and C APIs, as well as an official plugin for Unreal Engine.
Tutorial # 👉 The Tutorial is intended for novice to intermediate users. Step-by-step instructions on how to build a project with Band. Tutorial →
Quick Start # 👉 The Quick Start is intended for intermediate to advanced users. One page summary of how to build and customize Band. Quick Start →
Examples # See what others have build with Band. Example →
About Us # Find out who we are. About Us-\u0026gt;
`}),e.add({id:4,href:"/docs/getting-started/quick-start/",title:"Quick Start",description:"One page summary of how to use a Band.",content:`Prerequisites # Install Android SDK 28, NDK v19.2.53456
or create Visual Studio Code Dev Container using [root]/.devcontainer or utilize [root]/.devcontainer/Dockerfile Install Bazel
Install Bazelisk or Bazel We recommend to use Bazelisk to avoid version mismatch Configure Android SDK, NDK for build system
python configure.py How to build \u0026amp; run # Refer to detailed instructions in [root]/script
Run test
python script/run_test.py -android Build Android AAR
sh script/build_aar_armv8.sh Build C API
python script/build_c_api.py -android Run Benchmark
python script/run_benchmark.py --config band/test/data/benchmark_config.json `}),e.add({id:5,href:"/docs/getting-started/tutorial/",title:"Tutorial",description:"One page summary of how to use a Band.",content:"Requirements # Starts a new Android project # Starts a new C project # Starts a new Unreal Engine project # "}),e.add({id:6,href:"/docs/prologue/about-us/",title:"About Us",description:"Band is built and designed by a team `SNUMR` from Seoul National University Dept. of Computer Science and Engineering. We are cross-laboratory team from Software Platforms Lab and Human-Centered Computer-Systems Lab.",content:`Current Members # Youngki Lee, Byung-Gon Chun
Jingyu Lee, Changmin Jeon, Minjae Kim, Hyunsoo Kim, Seonjun Kim
Previous Members # Joo Seong Jeong, Donghyun Kim, Changjin Jeong
Citation # If you find our work useful, please cite our paper below! The original codebase for paper submission is archived here
@inproceedings{jeong2022band, title={Band: coordinated multi-DNN inference on heterogeneous mobile processors}, author={Jeong, Joo Seong and Lee, Jingyu and Kim, Donghyun and Jeon, Changmin and Jeong, Changjin and Lee, Youngki and Chun, Byung-Gon}, booktitle={Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services}, pages={235--247}, year={2022} } Acknowledgment # This work was supported by Samsung Research Funding \u0026amp; Incubation Center of Samsung Electronics under project number SRFC-IT2001-03.
`}),e.add({id:7,href:"/docs/getting-started/benchmark/",title:"Benchmark Tool",description:"One page summary of how to use a Benchmark Tool for Band.",content:`Band provides a simple C++ binary to benchmark a runtime performance. The binary generates repeatitive model requests based on a given config file, and reports latency statistics afterwards.
How to run # [root]/script/run_benchmark.py script will build band_benchmark binary file and execute it with a specified config file. Built binary file and target config file can be found in [root]/benchmark.
On Android # If you want to build binary from docker container (Refer to [root]/script/docker_util.sh for more detail)
python .\\script\\run_benchmark.py -android -docker -c .\\benchmark_config.json If you want to build locally
python .\\script\\run_benchmark.py -android -c .\\benchmark_config.json On local desktop (Windows or Ubuntu) # python .\\script\\run_benchmark.py -c .\\benchmark_config.json Config file # Structure # models: Models to run. For each model, specify the following fields. graph: Model path. period_ms: Optional The delay between subsequent requests in ms. The argument is only effective with periodic execution mode. batch_size: The number of model requests in a frame. [default: 1] worker_id: Optional Specify the worker id to run in int. The argument is only effective with fixed_device scheduler. slo_us and slo_scale: Optional fields for specifying an SLO value for a model. Setting slo_scale will make the SLO = worst profiled latency of that model * slo_scale. slo_scale will be ignored if slo_us is given (i.e., no reason to specify both options). log_path: The log file path. (e.g., /data/local/tmp/model_execution_log.json) schedulers: The scheduler types in list[string]. If N schedulers are specified, then N queues are generated. fixed_worker round_robin shortest_expected_latency least_slack_time_first heterogeneous_earliest_finish_time heterogeneous_earliest_finish_time_reserved minimum_subgraph_size: Minimum subgraph size. If candidate subgraph size is smaller than minimum_subgraph_size, the subgraph will not be created. [default: 7] subgraph_preparation_type: For schedulers using fallback, determine how to generate candidate subgraphs. [default: merge_unit_subgraph] no_fallback_subgraph: Generate subgraphs per worker. Explicit fallback subgraph will not be generated. fallback_per_worker: Generate fallback subgraphs for each worker. unit_subgraph: Generate unit subgraphs considering all device supportiveness. All ops in same unit subgraph have same support devices. merge_unit_subgraph: Add merged unit subgraphs to unit_subgraph. execution_mode: Specify a exeucution mode. Available execution modes are as follows: stream: consecutively run batches. periodic: invoke requests periodically. workload: execute pre-defined sequence in stream manner based on a given workload file. cpu_masks: CPU cluster mask to set CPU affinity. [default: ALL] ALL: All Cluster LITTLE: LITTLE Cluster only BIG: Big Cluster only PRIMARY: Primary Core only num_threads: Number of computing threads for CPU delegates. [default: -1] planner_cpu_masks: CPU cluster mask to set CPU affinity of planner. [default: same value as global cpu_masks] workers: A vector-like config for per-processor worker. For each worker, specify the following fields. System creates 1 worker per device by default and first provided value overrides the settings (i.e., cpu_masks, num_threads, profile_copy_computation_ratio, \u0026hellip; ) and additional field will add additional worker per device. device: Target device of specific worker. CPU GPU DSP NPU cpu_masks: CPU cluster mask to set CPU affinity of specific worker. [default: same value as global cpu_masks] num_threads: Number of threads. [default: same value as global num_threads] running_time_ms: Experiment duration in ms. [default: 60000] profile_smoothing_factor: Current profile reflection ratio. updated_profile = profile_smoothing_factor * curr_profile + (1 - profile_smoothing_factor) * prev_profile [default: 0.1] model_profile: The path to file with model profile results. [default: None] profile_online: Online profile or offline profile [default: true] profile_warmup_runs: Number of warmup runs before profile. [default: 1] profile_num_runs: Number of runs for profile. [default: 1] profile_copy_computation_ratio: Ratio of computation / input-ouput copy in list[int]. Used for latency estimation for each device type (e.g., CPU, GPU, DSP, NPU). The length of the list should be equal to the 4 (GetSize\u0026lt;DeviceFlags\u0026gt;()). [default: 30000, 30000, 30000, 30000] schedule_window_size: The number of planning unit. workload: The path to file with workload information. [default: None] Example # { \u0026quot;models\u0026quot;: [ { \u0026quot;graph\u0026quot;: \u0026quot;/data/local/tmp/model/lite-model_efficientdet_lite0_int8_1.tflite\u0026quot;, \u0026quot;period_ms\u0026quot;: 30, \u0026quot;batch_size\u0026quot;: 3 }, { \u0026quot;graph\u0026quot;: \u0026quot;/data/local/tmp/model/retinaface_mbv2_quant_160.tflite\u0026quot;, \u0026quot;period_ms\u0026quot;: 30, \u0026quot;batch_size\u0026quot;: 3 }, { \u0026quot;graph\u0026quot;: \u0026quot;/data/local/tmp/model/ssd_mobilenet_v1_1_metadata_1.tflite\u0026quot;, \u0026quot;period_ms\u0026quot;: 30, \u0026quot;batch_size\u0026quot;: 3 } ], \u0026quot;log_path\u0026quot;: \u0026quot;/data/local/tmp/log.json\u0026quot;, \u0026quot;schedulers\u0026quot;: [ \u0026quot;heterogeneous_earliest_finish_time_reserved\u0026quot; ], \u0026quot;minimum_subgraph_size\u0026quot;: 7, \u0026quot;subgraph_preparation_type\u0026quot;: \u0026quot;merge_unit_subgraph\u0026quot;, \u0026quot;execution_mode\u0026quot;: \u0026quot;stream\u0026quot;, \u0026quot;cpu_masks\u0026quot;: \u0026quot;ALL\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;planner_cpu_masks\u0026quot;: \u0026quot;PRIMARY\u0026quot;, \u0026quot;workers\u0026quot;: [ { \u0026quot;device\u0026quot;: \u0026quot;CPU\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;cpu_masks\u0026quot;: \u0026quot;BIG\u0026quot; }, { \u0026quot;device\u0026quot;: \u0026quot;CPU\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;cpu_masks\u0026quot;: \u0026quot;LITTLE\u0026quot; }, { \u0026quot;device\u0026quot;: \u0026quot;GPU\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;cpu_masks\u0026quot;: \u0026quot;ALL\u0026quot; }, { \u0026quot;device\u0026quot;: \u0026quot;DSP\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;cpu_masks\u0026quot;: \u0026quot;PRIMARY\u0026quot; }, { \u0026quot;device\u0026quot;: \u0026quot;NPU\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;cpu_masks\u0026quot;: \u0026quot;PRIMARY\u0026quot; } ], \u0026quot;running_time_ms\u0026quot;: 10000, \u0026quot;profile_smoothing_factor\u0026quot;: 0.1, \u0026quot;profile_data_path\u0026quot;: \u0026quot;/data/local/tmp/profile.json\u0026quot;, \u0026quot;profile_online\u0026quot;: true, \u0026quot;profile_warmup_runs\u0026quot;: 3, \u0026quot;profile_num_runs\u0026quot;: 50, \u0026quot;profile_copy_computation_ratio\u0026quot;: [ 1000, 1000, 1000, 1000 ], \u0026quot;availability_check_interval_ms\u0026quot;: 30000, \u0026quot;schedule_window_size\u0026quot;: 10 } `}),e.add({id:8,href:"/docs/getting-started/config/",title:"Config",description:"Configuration and its Builder for Band Runtime.",content:`There are four configuration objects for each Band\u0026rsquo;s component.
Each configuration field is optional or required. If a field is optional, then it is guaranteed that the default value exists. If a field is required, a configuration cannot be generated by RuntimeConfigBuilder without specifying the field.
Enumeration Types # SchedulerType
kBandFixedDeviceFixedWorker SchedulerType::RoundRobin SchedulerType::ShortestExpectedLatency kBandFixedDeviceFixedWorkerGlobalQueue SchedulerType::HeterogeneousEarliestFinishTime SchedulerType::LeastSlackTimeFirst SchedulerType::HeterogeneousEarliestFinishTimeReserved CPUMaskFlags
CPUMaskFlags::All CPUMaskFlags::Little CPUMaskFlags::Big CPUMaskFlags::Primary DeviceFlags
DeviceFlags::CPU DeviceFlags::GPU DeviceFlags::DSP DeviceFlags::NPU SubgraphPreparationType
SubgraphPreparationType::NoFallbackSubgraph SubgraphPreparationType::FallbackPerWorker SubgraphPreparationType::UnitSubgraph SubgraphPreparationType::MergeUnitSubgraph ProfileConfig # online [type: bool, default: true]: Profile online if true, offline if false. num_warmups [type: int, default: 1]: The number of warmup runs before profile. num_runs [type: int, default: 1]: The number of runs for profile copy_computation_ratio [type: std::vector\u0026lt;int\u0026gt;, default: [30000, ...]]: The ratio of computation to input-output copy. Used for latency estimation. The size of the list should be the same as the number of devices. smoothing_factor [type: float, default: 0.1]: The momentum to reflect current profiled data. \u0026lt;updateed_profile\u0026gt; = \u0026lt;smoothing_factor\u0026gt; * \u0026lt;curr_profile\u0026gt; + (1. - \u0026lt;smoothing_factor\u0026gt;) * \u0026lt;prev_profile\u0026gt;. profile_data_path [type: std::string, default: \u0026quot;\u0026quot;]: The input path to the file for offline profile results. If not specified, this will be ignored and will not generate the result file. PlannerConfig # schedule_window_size [type: int, default: INT_MAX]: The size of window that scheduler will use. schedulers [type: std::vector\u0026lt;SchedulerType\u0026gt;, required]: The types of schedulers. If N schedulers are specified, N queues will be generated. cpu_mask [type: CPUMaskFlags, default: CPUMaskFlags::All]: CPU masks to set CPU affinity. log_path [type: std::string, default: \u0026quot;\u0026quot;]: The output path to the file for planner\u0026rsquo;s log. If not specified, this will be ignored and will not generate the result file. WorkerConfig # workers [type: std::vector\u0026lt;DeviceFlags\u0026gt;, default: [DeviceFlags::CPU, DeviceFlags::GPU, ...]]: The list of target devices. By default, one worker per device is generated. cpu_masks [type: std::vector\u0026lt;CPUMaskFlags\u0026gt;, default: [CPUMaskFlags::All, CPUMaskFlags::All, ...]]: CPU masks to set CPU affinity. The size of the list must be the same as the size of workers. num_threads [type: std::vector\u0026lt;int\u0026gt;, default: [1, 1, ...]]: The number of threads. The size of the list must be the same as the size of workers. allow_worksteal [type: bool, default: false]: Work-stealing is enabled if true, disabled if false. availability_check_interval_ms [type: int, default: 30_000]: The interval for checking availability of devices. Used for detecting thermal throttling. RuntimeConfig # RuntimeConfig contains ProfileConfig, PlannerConfig and WorkerConfig. minimum_subgraph_size [type: int, default: 7]: The minimum subgraph size. If candidate subgraph size is smaller than this, the subgraph will not be created. subgraph_preparation_type [type: SubgraphPreparationType, default: SubgraphPreparationType::MergeUnitSubgraph]: For fallback schedulers, determine how to generate candidate subgraphs. cpu_mask [type: CPUMaskFlags, default: CPUMaskFlags::All]: The CPU mask for Band Engine. RuntimeConfigBuilder API # RuntimeConfigBuilder delegates all builder that inherits ConfigBuilder. It is a friend class of all the other ConfigBuilder classes, so make sure to not change their members in RuntimeConfigBuilder.
Exmaple Usage # RuntimeConfigBuilder b; auto config = b.AddOnline(false) // Default was \`true\` .AddSmoothingFactor(0.3) // Default was \`0.1\` .AddSchedulers({SchedulerType::RoundRobin, SchedulerType::LeastSlackTimeFirst}) // Required field. .Build(); Methods # All Add* methods are idempotent, i.e. multiple calls behaves the same as a single call.
AddOnline(bool online) AddNumWarmups(int num_warmups) AddNumRuns(int num_runs) AddCopyComputationRatio(std::vector\u0026lt;int\u0026gt; copy_computation_ratio) AddSmoothingFactor(float smoothing_factor) AddProfileLogPath(std::string profile_data_path) AddPlannerLogPath(std::string planner_log_path) AddScheduleWindowSize(int schedule_window_size) AddSchedulers(std::vector\u0026lt;SchedulerType\u0026gt; schedulers) AddPlannerCPUMask(CPUMaskFlags cpu_masks) AddWorkers(std::vector\u0026lt;DeviceFlags\u0026gt; workers) AddWorkerCPUMasks(std::vector\u0026lt;CPUMaskFlags\u0026gt; cpu_masks) AddWorkerNumThreads(std::vector\u0026lt;int\u0026gt; num_threads) AddAllowWorkSteal(bool allow_worksteal) AddAvailabilityCheckIntervalMs(int32_t availability_check_interval_ms) AddMinimumSubgraphSize(int minimum_subgraph_size) AddSubgraphPreparationType(SubgraphPreparationType subgraph_preparation_type) AddCPUMask(CPUMaskFlags cpu_mask) `}),e.add({id:9,href:"/docs/api/c/",title:"C",description:"One page summary of how to use a C API.",content:""}),e.add({id:10,href:"/docs/api/java/",title:"Java",description:"One page summary of how to use a Java API.",content:""}),e.add({id:11,href:"/docs/api/unreal-plugin/",title:"Unreal Engine Plugin",description:"One page summary of how to use a Unreal Engine Plugin.",content:""}),e.add({id:12,href:"/docs/",title:"Docs",description:"Docs Doks.",content:""}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()