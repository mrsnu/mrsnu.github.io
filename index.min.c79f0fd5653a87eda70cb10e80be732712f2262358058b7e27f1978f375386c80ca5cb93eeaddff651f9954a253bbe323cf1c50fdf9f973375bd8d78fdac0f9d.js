var suggestions = document.getElementById('suggestions');
var search = document.getElementById('search');

if (search !== null) {
  document.addEventListener('keydown', inputFocus);
}

function inputFocus(e) {
  if (e.ctrlKey && e.key === '/' ) {
    e.preventDefault();
    search.focus();
  }
  if (e.key === 'Escape' ) {
    search.blur();
    suggestions.classList.add('d-none');
  }
}

document.addEventListener('click', function(event) {

  var isClickInsideElement = suggestions.contains(event.target);

  if (!isClickInsideElement) {
    suggestions.classList.add('d-none');
  }

});

/*
Source:
  - https://dev.to/shubhamprakash/trap-focus-using-javascript-6a3
*/

document.addEventListener('keydown',suggestionFocus);

function suggestionFocus(e) {
  const suggestionsHidden = suggestions.classList.contains('d-none');
  if (suggestionsHidden) return;

  const focusableSuggestions= [...suggestions.querySelectorAll('a')];
  if (focusableSuggestions.length === 0) return;

  const index = focusableSuggestions.indexOf(document.activeElement);

  if (e.key === "ArrowUp") {
    e.preventDefault();
    const nextIndex = index > 0 ? index - 1 : 0;
    focusableSuggestions[nextIndex].focus();
  }
  else if (e.key === "ArrowDown") {
    e.preventDefault();
    const nextIndex= index + 1 < focusableSuggestions.length ? index + 1 : index;
    focusableSuggestions[nextIndex].focus();
  }

}

/*
Source:
  - https://github.com/nextapps-de/flexsearch#index-documents-field-search
  - https://raw.githack.com/nextapps-de/flexsearch/master/demo/autocomplete.html
*/

(function(){

  var index = new FlexSearch.Document({
    tokenize: "forward",
    cache: 100,
    document: {
      id: 'id',
      store: [
        "href", "title", "description"
      ],
      index: ["title", "description", "content"]
    }
  });


  // Not yet supported: https://github.com/nextapps-de/flexsearch#complex-documents

  /*
  var docs = [
    {
        id: 0,
        href: "https://mrsnu.github.io/docs/prologue/",
        title: "Prologue",
        description: "Prologue Doks.",
        content: ""
      },
    {
        id: 1,
        href: "https://mrsnu.github.io/docs/getting-started/",
        title: "Getting Started",
        description: "Getting Started",
        content: ""
      },
    {
        id: 2,
        href: "https://mrsnu.github.io/docs/api/",
        title: "API",
        description: "API",
        content: ""
      },
    {
        id: 3,
        href: "https://mrsnu.github.io/docs/prologue/introduction/",
        title: "Introduction",
        description: "",
        content: "\u003cp\u003e\u003ca href=\"https://dl.acm.org/doi/10.1145/3498361.3538948\"\u003eBand\u003c/a\u003e is an efficient deep learning platform for mobile-cloud collaborative support for multiple DNNs.\nBand supports backend-agnostic coordination of DNN requests on heterogeneous processors in a mobile device to \u003cs\u003ecloud server\u003c/s\u003e.\nBand is currently backed by following backend machine learning frameworks.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003e\u003ca href=\"https://github.com/tensorflow/tensorflow/tree/v2.9.2\"\u003eTensorflow v2.9.2\u003c/a\u003e\u003c/th\u003e\n\u003cth\u003e\u0026hellip;\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eAndroid\u003c/td\u003e\n\u003ctd\u003eâ˜‘\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eiOS\u003c/td\u003e\n\u003ctd\u003eâ˜\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egRPC\u003c/td\u003e\n\u003ctd\u003eâ˜\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eBand provides Java and C APIs, as well as an official plugin for \u003ca href=\"https://www.unrealengine.com/\"\u003eUnreal Engine\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"quick-start\"\u003eQuick Start \u003ca href=\"#quick-start\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cdiv class=\"alert alert-doks d-flex\" role=\"alert\"\u003e\n  \u003cdiv class=\"flex-shrink-1 alert-icon\"\u003eðŸ‘‰ \u003c/div\u003e\n  \n    \u003cdiv class=\"w-100\"\u003eThe Quick Start is intended for intermediate to advanced users. \u003c/div\u003e\n  \n\u003c/div\u003e\n\n\u003cp\u003eOne page summary of how to build and customize Band. \u003ca href=\"/docs/getting-started/quick-start/\"\u003eQuick Start â†’\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"examples\"\u003eExamples \u003ca href=\"#examples\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eSee what others have build with Band. \u003ca href=\"/example/\"\u003eExample â†’\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"about-us\"\u003eAbout Us \u003ca href=\"#about-us\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eFind out who we are. \u003ca href=\"/docs/prologue/about-us/\"\u003eAbout Us-\u0026gt;\u003c/a\u003e\u003c/p\u003e\n"
      },
    {
        id: 4,
        href: "https://mrsnu.github.io/docs/getting-started/quick-start/",
        title: "Quick Start",
        description: "One page summary of how to use a Band.",
        content: "\u003ch3 id=\"prerequisites\"\u003ePrerequisites \u003ca href=\"#prerequisites\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eInstall Android SDK 28, NDK v19.2.53456\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eor create \u003ca href=\"https://code.visualstudio.com/docs/devcontainers/containers\"\u003eVisual Studio Code Dev Container\u003c/a\u003e using \u003ccode\u003e[root]/.devcontainer\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eor utilize \u003ccode\u003e[root]/.devcontainer/Dockerfile\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInstall Bazel\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInstall \u003ca href=\"https://github.com/bazelbuild/bazelisk\"\u003eBazelisk\u003c/a\u003e or \u003ca href=\"https://docs.bazel.build/versions/master/install.html\"\u003eBazel\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWe recommend to use Bazelisk to avoid version mismatch\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eConfigure Android SDK, NDK for build system\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003epython configure.py\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"how-to-build--run\"\u003eHow to build \u0026amp; run \u003ca href=\"#how-to-build--run\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eRefer to detailed instructions in \u003ccode\u003e[root]/script\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eRun test\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003epython script/run_test.py -android \n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBuild Android AAR\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003esh script/build_aar_armv8.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBuild C API\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003epython script/build_c_api.py -android \n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRun \u003ca href=\"/docs/getting-started/benchmark/\"\u003eBenchmark\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003epython script/run_benchmark.py --config band/test/data/benchmark_config.json\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
    {
        id: 5,
        href: "https://mrsnu.github.io/docs/prologue/about-us/",
        title: "About Us",
        description: "Band is built and designed by the team `SNUMR` from Seoul National University Dept. of Computer Science and Engineering. We are cross-laboratory team from Software Platforms Lab and Human-Centered Computer-Systems Lab.",
        content: "\u003ch3 id=\"current-members\"\u003eCurrent Members \u003ca href=\"#current-members\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"http://youngkilee.blogspot.com/\"\u003eYoungki Lee\u003c/a\u003e,\n\u003ca href=\"https://bgchun.github.io/\"\u003eByung-Gon Chun\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://jingyulee.com/\"\u003eJingyu Lee\u003c/a\u003e,\n\u003ca href=\"https://changminjeon.com/\"\u003eChangmin Jeon\u003c/a\u003e,\nMinjae Kim,\nHyunsoo Kim,\nSeonjun Kim\u003c/p\u003e\n\u003ch3 id=\"previous-members\"\u003ePrevious Members \u003ca href=\"#previous-members\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eJoo Seong Jeong,\nDonghyun Kim,\nChangjin Jeong\u003c/p\u003e\n\u003ch3 id=\"citation\"\u003eCitation \u003ca href=\"#citation\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eIf you find our work useful, please cite our paper below!\nThe original codebase for paper submission is archived \u003ca href=\"https://github.com/mrsnu/band/releases/tag/v0.0.0\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bibtex\"\u003e@inproceedings{jeong2022band,\n  title={Band: coordinated multi-DNN inference on heterogeneous mobile processors},\n  author={Jeong, Joo Seong and Lee, Jingyu and Kim, Donghyun and Jeon, Changmin and Jeong, Changjin and Lee, Youngki and Chun, Byung-Gon},\n  booktitle={Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services},\n  pages={235--247},\n  year={2022}\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"acknowledgment\"\u003eAcknowledgment \u003ca href=\"#acknowledgment\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThis work was supported by Samsung Research Funding \u0026amp; Incubation Center of Samsung Electronics under project number SRFC-IT2001-03.\u003c/p\u003e\n"
      },
    {
        id: 6,
        href: "https://mrsnu.github.io/docs/getting-started/benchmark/",
        title: "Benchmark Tool",
        description: "One page summary of how to use a Benchmark Tool for Band.",
        content: "\u003cp\u003eBand provides a simple C++ binary to benchmark a runtime performance.\nThe binary generates repeatitive model requests based on a given config file, and reports latency statistics afterwards.\u003c/p\u003e\n\u003ch2 id=\"how-to-run\"\u003eHow to run \u003ca href=\"#how-to-run\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003e[root]/script/run_benchmark.py\u003c/code\u003e script will build \u003ccode\u003eband_benchmark\u003c/code\u003e binary file and execute it with a specified config file. Built binary file and target config file can be found in \u003ccode\u003e[root]/benchmark\u003c/code\u003e.\u003c/p\u003e\n\u003ch3 id=\"on-android\"\u003eOn Android \u003ca href=\"#on-android\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eIf you want to build binary from docker container (Refer to \u003ccode\u003e[root]/script/docker_util.sh\u003c/code\u003e for more detail)\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003epython .\\script\\run_benchmark.py -android -docker -c .\\benchmark_config.json\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf you want to build locally\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003epython .\\script\\run_benchmark.py -android -c .\\benchmark_config.json\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"on-local-desktop-windows-or-ubuntu\"\u003eOn local desktop (Windows or Ubuntu) \u003ca href=\"#on-local-desktop-windows-or-ubuntu\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003epython .\\script\\run_benchmark.py -c .\\benchmark_config.json\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"config-file\"\u003eConfig file \u003ca href=\"#config-file\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"structure\"\u003eStructure \u003ca href=\"#structure\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emodels\u003c/code\u003e: Models to run. For each model, specify the following fields.\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003egraph\u003c/code\u003e: Model path.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eperiod_ms\u003c/code\u003e: \u003cstrong\u003eOptional\u003c/strong\u003e The delay between subsequent requests in ms. The argument is only effective with \u003ccode\u003eperiodic\u003c/code\u003e execution mode.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ebatch_size\u003c/code\u003e: The number of model requests in a frame. [default: 1]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eworker_id\u003c/code\u003e: \u003cstrong\u003eOptional\u003c/strong\u003e Specify the worker id to run in int. The argument is only effective with \u003ccode\u003efixed_device\u003c/code\u003e scheduler.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eslo_us\u003c/code\u003e and \u003ccode\u003eslo_scale\u003c/code\u003e: \u003cstrong\u003eOptional\u003c/strong\u003e fields for specifying an SLO value for a model. Setting \u003ccode\u003eslo_scale\u003c/code\u003e will make the SLO = worst profiled latency of that model * \u003ccode\u003eslo_scale\u003c/code\u003e. \u003ccode\u003eslo_scale\u003c/code\u003e will be ignored if \u003ccode\u003eslo_us\u003c/code\u003e is given (i.e., no reason to specify both options).\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elog_path\u003c/code\u003e: The log file path. (e.g., \u003ccode\u003e/data/local/tmp/model_execution_log.json\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eschedulers\u003c/code\u003e: The scheduler types in \u003ccode\u003elist[string]\u003c/code\u003e. If N schedulers are specified, then N queues are generated.\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003efixed_worker\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eround_robin\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eshortest_expected_latency\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eleast_slack_time_first\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eheterogeneous_earliest_finish_time\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eheterogeneous_earliest_finish_time_reserved\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eminimum_subgraph_size\u003c/code\u003e: Minimum subgraph size. If candidate subgraph size is smaller than \u003ccode\u003eminimum_subgraph_size\u003c/code\u003e, the subgraph will not be created. [default: 7]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esubgraph_preparation_type\u003c/code\u003e: For schedulers using fallback, determine how to generate candidate subgraphs. [default: \u003ccode\u003emerge_unit_subgraph\u003c/code\u003e]\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eno_fallback_subgraph\u003c/code\u003e: Generate subgraphs per worker. Explicit fallback subgraph will not be generated.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003efallback_per_worker\u003c/code\u003e: Generate fallback subgraphs for each worker.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eunit_subgraph\u003c/code\u003e: Generate unit subgraphs considering all device supportiveness. All ops in same unit subgraph have same support devices.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emerge_unit_subgraph\u003c/code\u003e: Add merged unit subgraphs to \u003ccode\u003eunit_subgraph\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eexecution_mode\u003c/code\u003e: Specify a exeucution mode. Available execution modes are as follows:\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003estream\u003c/code\u003e: consecutively run batches.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eperiodic\u003c/code\u003e: invoke requests periodically.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eworkload\u003c/code\u003e: execute pre-defined sequence in \u003ccode\u003estream\u003c/code\u003e manner based on a given workload file.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecpu_masks\u003c/code\u003e: CPU cluster mask to set CPU affinity. [default: \u003ccode\u003eALL\u003c/code\u003e]\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eALL\u003c/code\u003e: All Cluster\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eLITTLE\u003c/code\u003e: LITTLE Cluster only\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBIG\u003c/code\u003e: Big Cluster only\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ePRIMARY\u003c/code\u003e: Primary Core only\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enum_threads\u003c/code\u003e: Number of computing threads for CPU delegates. [default: -1]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eplanner_cpu_masks\u003c/code\u003e: CPU cluster mask to set CPU affinity of planner. [default: same value as global \u003ccode\u003ecpu_masks\u003c/code\u003e]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eworkers\u003c/code\u003e: A vector-like config for per-processor worker. For each worker, specify the following fields. System creates 1 worker per device by default and first provided value overrides the settings (i.e., \u003ccode\u003ecpu_masks\u003c/code\u003e, \u003ccode\u003enum_threads\u003c/code\u003e, \u003ccode\u003eprofile_copy_computation_ratio\u003c/code\u003e, \u0026hellip; ) and additional field will add additional worker per device.\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edevice\u003c/code\u003e: Target device of specific worker.\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eCPU\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eGPU\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eDSP\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eNPU\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecpu_masks\u003c/code\u003e: CPU cluster mask to set CPU affinity of specific worker. [default: same value as global \u003ccode\u003ecpu_masks\u003c/code\u003e]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enum_threads\u003c/code\u003e: Number of threads. [default: same value as global \u003ccode\u003enum_threads\u003c/code\u003e]\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erunning_time_ms\u003c/code\u003e: Experiment duration in ms. [default: 60000]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eprofile_smoothing_factor\u003c/code\u003e: Current profile reflection ratio. \u003ccode\u003eupdated_profile = profile_smoothing_factor * curr_profile + (1 - profile_smoothing_factor) * prev_profile\u003c/code\u003e [default: 0.1]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emodel_profile\u003c/code\u003e: The path to file with model profile results. [default: None]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eprofile_online\u003c/code\u003e: Online profile or offline profile [default: true]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eprofile_warmup_runs\u003c/code\u003e: Number of warmup runs before profile. [default: 1]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eprofile_num_runs\u003c/code\u003e: Number of runs for profile. [default: 1]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eprofile_copy_computation_ratio\u003c/code\u003e: Ratio of computation / input-ouput copy in \u003ccode\u003elist[int]\u003c/code\u003e. Used for latency estimation for each device type (e.g., CPU, GPU, DSP, NPU). The length of the list should be equal to the 4 (\u003ccode\u003eGetSize\u0026lt;DeviceFlags\u0026gt;()\u003c/code\u003e). [default: 30000, 30000, 30000, 30000]\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eschedule_window_size\u003c/code\u003e: The number of planning unit.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eworkload\u003c/code\u003e: The path to file with workload information. [default: None]\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"example\"\u003eExample \u003ca href=\"#example\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;models\u0026quot;: [\n        {\n            \u0026quot;graph\u0026quot;: \u0026quot;/data/local/tmp/model/lite-model_efficientdet_lite0_int8_1.tflite\u0026quot;,\n            \u0026quot;period_ms\u0026quot;: 30,\n            \u0026quot;batch_size\u0026quot;: 3\n        },\n        {\n            \u0026quot;graph\u0026quot;: \u0026quot;/data/local/tmp/model/retinaface_mbv2_quant_160.tflite\u0026quot;,\n            \u0026quot;period_ms\u0026quot;: 30,\n            \u0026quot;batch_size\u0026quot;: 3\n        },\n        {\n            \u0026quot;graph\u0026quot;: \u0026quot;/data/local/tmp/model/ssd_mobilenet_v1_1_metadata_1.tflite\u0026quot;,\n            \u0026quot;period_ms\u0026quot;: 30,\n            \u0026quot;batch_size\u0026quot;: 3\n        }\n    ],\n    \u0026quot;log_path\u0026quot;: \u0026quot;/data/local/tmp/log.json\u0026quot;,\n    \u0026quot;schedulers\u0026quot;: [\n        \u0026quot;heterogeneous_earliest_finish_time_reserved\u0026quot;\n    ],\n    \u0026quot;minimum_subgraph_size\u0026quot;: 7,\n    \u0026quot;subgraph_preparation_type\u0026quot;: \u0026quot;merge_unit_subgraph\u0026quot;,\n    \u0026quot;execution_mode\u0026quot;: \u0026quot;stream\u0026quot;,\n    \u0026quot;cpu_masks\u0026quot;: \u0026quot;ALL\u0026quot;,\n    \u0026quot;num_threads\u0026quot;: 1,\n    \u0026quot;planner_cpu_masks\u0026quot;: \u0026quot;PRIMARY\u0026quot;,\n    \u0026quot;workers\u0026quot;: [\n        {\n            \u0026quot;device\u0026quot;: \u0026quot;CPU\u0026quot;,\n            \u0026quot;num_threads\u0026quot;: 1,\n            \u0026quot;cpu_masks\u0026quot;: \u0026quot;BIG\u0026quot;\n        },\n        {\n            \u0026quot;device\u0026quot;: \u0026quot;CPU\u0026quot;,\n            \u0026quot;num_threads\u0026quot;: 1,\n            \u0026quot;cpu_masks\u0026quot;: \u0026quot;LITTLE\u0026quot;\n        },\n        {\n            \u0026quot;device\u0026quot;: \u0026quot;GPU\u0026quot;,\n            \u0026quot;num_threads\u0026quot;: 1,\n            \u0026quot;cpu_masks\u0026quot;: \u0026quot;ALL\u0026quot;\n        },\n        {\n            \u0026quot;device\u0026quot;: \u0026quot;DSP\u0026quot;,\n            \u0026quot;num_threads\u0026quot;: 1,\n            \u0026quot;cpu_masks\u0026quot;: \u0026quot;PRIMARY\u0026quot;\n        },\n        {\n            \u0026quot;device\u0026quot;: \u0026quot;NPU\u0026quot;,\n            \u0026quot;num_threads\u0026quot;: 1,\n            \u0026quot;cpu_masks\u0026quot;: \u0026quot;PRIMARY\u0026quot;\n        }\n    ],\n    \u0026quot;running_time_ms\u0026quot;: 10000,\n    \u0026quot;profile_smoothing_factor\u0026quot;: 0.1,\n    \u0026quot;profile_data_path\u0026quot;: \u0026quot;/data/local/tmp/profile.json\u0026quot;,\n    \u0026quot;profile_online\u0026quot;: true,\n    \u0026quot;profile_warmup_runs\u0026quot;: 3,\n    \u0026quot;profile_num_runs\u0026quot;: 50,\n    \u0026quot;profile_copy_computation_ratio\u0026quot;: [\n        1000,\n        1000,\n        1000,\n        1000\n    ],\n    \u0026quot;availability_check_interval_ms\u0026quot;: 30000,\n    \u0026quot;schedule_window_size\u0026quot;: 10\n}\n\u003c/code\u003e\u003c/pre\u003e\n"
      },
    {
        id: 7,
        href: "https://mrsnu.github.io/docs/getting-started/config/",
        title: "Config",
        description: "Configuration and its Builder for Band Runtime.",
        content: "\u003cp\u003eThere are four configuration objects for each Band\u0026rsquo;s component.\u003c/p\u003e\n\u003cp\u003eEach configuration field is optional or required. If a field is optional, then it is guaranteed that the default value exists. If a field is required, a configuration cannot be generated by \u003ccode\u003eRuntimeConfigBuilder\u003c/code\u003e without specifying the field.\u003c/p\u003e\n\u003ch3 id=\"enumeration-types\"\u003eEnumeration Types \u003ca href=\"#enumeration-types\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eSchedulerType\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ekBandFixedDeviceFixedWorker\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSchedulerType::RoundRobin\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSchedulerType::ShortestExpectedLatency\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekBandFixedDeviceFixedWorkerGlobalQueue\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSchedulerType::HeterogeneousEarliestFinishTime\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSchedulerType::LeastSlackTimeFirst\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSchedulerType::HeterogeneousEarliestFinishTimeReserved\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eCPUMaskFlags\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eCPUMaskFlags::All\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eCPUMaskFlags::Little\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eCPUMaskFlags::Big\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eCPUMaskFlags::Primary\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eDeviceFlags\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eDeviceFlags::CPU\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eDeviceFlags::GPU\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eDeviceFlags::DSP\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eDeviceFlags::NPU\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eSubgraphPreparationType\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eSubgraphPreparationType::NoFallbackSubgraph\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSubgraphPreparationType::FallbackPerWorker\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSubgraphPreparationType::UnitSubgraph\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSubgraphPreparationType::MergeUnitSubgraph\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"profileconfig\"\u003e\u003ccode\u003eProfileConfig\u003c/code\u003e \u003ca href=\"#profileconfig\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eonline\u003c/code\u003e [type: \u003ccode\u003ebool\u003c/code\u003e, default: \u003ccode\u003etrue\u003c/code\u003e]: Profile online if true, offline if false.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enum_warmups\u003c/code\u003e [type: \u003ccode\u003eint\u003c/code\u003e, default: \u003ccode\u003e1\u003c/code\u003e]: The number of warmup runs before profile.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enum_runs\u003c/code\u003e [type: \u003ccode\u003eint\u003c/code\u003e, default: \u003ccode\u003e1\u003c/code\u003e]: The number of runs for profile\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecopy_computation_ratio\u003c/code\u003e [type: \u003ccode\u003estd::vector\u0026lt;int\u0026gt;\u003c/code\u003e, default: \u003ccode\u003e[30000, ...]\u003c/code\u003e]: The ratio of computation to input-output copy. Used for latency estimation. The size of the list should be the same as the number of devices.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esmoothing_factor\u003c/code\u003e [type: \u003ccode\u003efloat\u003c/code\u003e, default: \u003ccode\u003e0.1\u003c/code\u003e]: The momentum to reflect current profiled data. \u003ccode\u003e\u0026lt;updateed_profile\u0026gt; = \u0026lt;smoothing_factor\u0026gt; * \u0026lt;curr_profile\u0026gt; + (1. - \u0026lt;smoothing_factor\u0026gt;) * \u0026lt;prev_profile\u0026gt;\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eprofile_data_path\u003c/code\u003e [type: \u003ccode\u003estd::string\u003c/code\u003e, default: \u003ccode\u003e\u0026quot;\u0026quot;\u003c/code\u003e]: The input path to the file for offline profile results. If not specified, this will be ignored and will not generate the result file.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"plannerconfig\"\u003e\u003ccode\u003ePlannerConfig\u003c/code\u003e \u003ca href=\"#plannerconfig\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eschedule_window_size\u003c/code\u003e [type: \u003ccode\u003eint\u003c/code\u003e, default: \u003ccode\u003eINT_MAX\u003c/code\u003e]: The size of window that scheduler will use.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eschedulers\u003c/code\u003e [type: \u003ccode\u003estd::vector\u0026lt;SchedulerType\u0026gt;\u003c/code\u003e, \u003cstrong\u003erequired\u003c/strong\u003e]: The types of schedulers. If \u003ccode\u003eN\u003c/code\u003e schedulers are specified, \u003ccode\u003eN\u003c/code\u003e queues will be generated.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecpu_mask\u003c/code\u003e [type: \u003ccode\u003eCPUMaskFlags\u003c/code\u003e, default: \u003ccode\u003eCPUMaskFlags::All\u003c/code\u003e]: CPU masks to set CPU affinity.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elog_path\u003c/code\u003e [type: \u003ccode\u003estd::string\u003c/code\u003e, default: \u003ccode\u003e\u0026quot;\u0026quot;\u003c/code\u003e]: The output path to the file for planner\u0026rsquo;s log. If not specified, this will be ignored and will not generate the result file.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"workerconfig\"\u003e\u003ccode\u003eWorkerConfig\u003c/code\u003e \u003ca href=\"#workerconfig\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eworkers\u003c/code\u003e [type: \u003ccode\u003estd::vector\u0026lt;DeviceFlags\u0026gt;\u003c/code\u003e, default: \u003ccode\u003e[DeviceFlags::CPU, DeviceFlags::GPU, ...]\u003c/code\u003e]: The list of target devices. By default, one worker per device is generated.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecpu_masks\u003c/code\u003e [type: \u003ccode\u003estd::vector\u0026lt;CPUMaskFlags\u0026gt;\u003c/code\u003e, default: \u003ccode\u003e[CPUMaskFlags::All, CPUMaskFlags::All, ...]\u003c/code\u003e]: CPU masks to set CPU affinity. The size of the list must be the same as the size of \u003ccode\u003eworkers\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enum_threads\u003c/code\u003e [type: \u003ccode\u003estd::vector\u0026lt;int\u0026gt;\u003c/code\u003e, default: \u003ccode\u003e[1, 1, ...]\u003c/code\u003e]: The number of threads. The size of the list must be the same as the size of \u003ccode\u003eworkers\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eallow_worksteal\u003c/code\u003e [type: \u003ccode\u003ebool\u003c/code\u003e, default: \u003ccode\u003efalse\u003c/code\u003e]: Work-stealing is enabled if true, disabled if false.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eavailability_check_interval_ms\u003c/code\u003e [type: \u003ccode\u003eint\u003c/code\u003e, default: \u003ccode\u003e30_000\u003c/code\u003e]: The interval for checking availability of devices. Used for detecting thermal throttling.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"runtimeconfig\"\u003e\u003ccode\u003eRuntimeConfig\u003c/code\u003e \u003ca href=\"#runtimeconfig\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eRuntimeConfig\u003c/code\u003e contains \u003ccode\u003eProfileConfig\u003c/code\u003e, \u003ccode\u003ePlannerConfig\u003c/code\u003e and \u003ccode\u003eWorkerConfig\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eminimum_subgraph_size\u003c/code\u003e [type: \u003ccode\u003eint\u003c/code\u003e, default: \u003ccode\u003e7\u003c/code\u003e]: The minimum subgraph size. If candidate subgraph size is smaller than this, the subgraph will not be created.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esubgraph_preparation_type\u003c/code\u003e [type: \u003ccode\u003eSubgraphPreparationType\u003c/code\u003e, default: \u003ccode\u003eSubgraphPreparationType::MergeUnitSubgraph\u003c/code\u003e]: For fallback schedulers, determine how to generate candidate subgraphs.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecpu_mask\u003c/code\u003e [type: \u003ccode\u003eCPUMaskFlags\u003c/code\u003e, default: \u003ccode\u003eCPUMaskFlags::All\u003c/code\u003e]: The CPU mask for Band Engine.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"runtimeconfigbuilder-api\"\u003e\u003ccode\u003eRuntimeConfigBuilder\u003c/code\u003e API \u003ca href=\"#runtimeconfigbuilder-api\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eRuntimeConfigBuilder\u003c/code\u003e delegates all builder that inherits \u003ccode\u003eConfigBuilder\u003c/code\u003e.\nIt is a \u003ccode\u003efriend\u003c/code\u003e class of all the other \u003ccode\u003eConfigBuilder\u003c/code\u003e classes, so make sure to not change their members in \u003ccode\u003eRuntimeConfigBuilder\u003c/code\u003e.\u003c/p\u003e\n\u003ch3 id=\"exmaple-usage\"\u003eExmaple Usage \u003ca href=\"#exmaple-usage\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c++\"\u003eRuntimeConfigBuilder b;\nauto config = b.AddOnline(false)  // Default was `true`\n                  .AddSmoothingFactor(0.3)  // Default was `0.1`\n                  .AddSchedulers({SchedulerType::RoundRobin, SchedulerType::LeastSlackTimeFirst})  // Required field.\n                  .Build();\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"methods\"\u003eMethods \u003ca href=\"#methods\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eAll \u003ccode\u003eAdd*\u003c/code\u003e methods are idempotent, i.e. multiple calls behaves the same as a single call.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eAddOnline(bool online)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddNumWarmups(int num_warmups)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddNumRuns(int num_runs)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddCopyComputationRatio(std::vector\u0026lt;int\u0026gt; copy_computation_ratio)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddSmoothingFactor(float smoothing_factor)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddProfileLogPath(std::string profile_data_path)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddPlannerLogPath(std::string planner_log_path)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddScheduleWindowSize(int schedule_window_size)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddSchedulers(std::vector\u0026lt;SchedulerType\u0026gt; schedulers)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddPlannerCPUMask(CPUMaskFlags cpu_masks)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddWorkers(std::vector\u0026lt;DeviceFlags\u0026gt; workers)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddWorkerCPUMasks(std::vector\u0026lt;CPUMaskFlags\u0026gt; cpu_masks)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddWorkerNumThreads(std::vector\u0026lt;int\u0026gt; num_threads)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddAllowWorkSteal(bool allow_worksteal)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddAvailabilityCheckIntervalMs(int32_t availability_check_interval_ms)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddMinimumSubgraphSize(int minimum_subgraph_size)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddSubgraphPreparationType(SubgraphPreparationType subgraph_preparation_type)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eAddCPUMask(CPUMaskFlags cpu_mask)\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
    {
        id: 8,
        href: "https://mrsnu.github.io/docs/api/c/",
        title: "C",
        description: "One page summary of how to use a C API.",
        content: "\u003ch2 id=\"introduction\"\u003eIntroduction \u003ca href=\"#introduction\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eBand provides a C API for developers who want to use Band in their C/C++ projects. The API is a thin wrapper around the core C++ API. The C API is available in the \u003ccode\u003elibband.h\u003c/code\u003e header file.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/mrsnu/band/blob/master/band/c/example/band_c_main.c\"\u003eLink\u003c/a\u003e provides a complete example of how to dynamically load the library and use the C API.\u003c/p\u003e\n\u003ch3 id=\"example\"\u003eExample \u003ca href=\"#example\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003e#include \u0026lt;libband.h\u0026gt;\n\nint main() {\n  // 1. Create a configuration for the engine.\n  BandConfigBuilder* b = BandConfigBuilderCreate();\n  BandAddConfig(b, BAND_PLANNER_LOG_PATH, /*count=*/1, \u0026quot;log.json\u0026quot;);\n  BandAddConfig(b, BAND_PLANNER_SCHEDULERS, /*count=*/1, kBandHeterogeneousEarliestFinishTime);\n  BandConfig* config = BandConfigCreate(b);\n\n  // 2. Create an engine.\n  BandEngine* engine = BandEngineCreate(config);\n\n  // 3. Create and register a model.\n  BandModel* model = BandModelCreate();\n  BandModelAddFromFile(model, kBandTfLite,\n                        \u0026quot;mobilenet_v2_1.0_224_quant.tflite\u0026quot;);\n  BandEngineRegisterModel(engine, model);\n\n  // 4. Create input and output tensors for the model.\n  BandTensor* input_tensor = BandEngineCreateInputTensor(engine, model, 0);\n  BandTensor* output_tensor = BandEngineCreateOutputTensor(engine, model, 0);\n  std::tuple\u0026lt;unsigned char*, int, int\u0026gt; image_buffer =\n      LoadRGBImageRaw(\u0026quot;cat.jpg\u0026quot;);\n\n  // 5. (Optional) Create a buffer and an image processor to initialize the\n  // input tensor with the image data.\n  BandBuffer* buffer = BandBufferCreate();\n  BandBufferSetFromRawData(buffer, std::get\u0026lt;0\u0026gt;(image_buffer),\n                            std::get\u0026lt;1\u0026gt;(image_buffer), std::get\u0026lt;2\u0026gt;(image_buffer),\n                            kBandRGB);\n\n  BandImageProcessorBuilder* builder = BandImageProcessorBuilderCreate();\n  BandImageProcessor* processor = BandImageProcessorBuilderBuild(builder);\n  BandImageProcessorProcess(processor, buffer, input_tensor);\n\n  // 6. Run the model.\n  BandEngineRequestSync(engine, model, \u0026amp;input_tensor, \u0026amp;output_tensor);\n  \n  // 7. Get the result (class index).\n  unsigned char* output =\n      static_cast\u0026lt;unsigned char*\u0026gt;(BandTensorGetData(output_tensor));\n  // should be 282 (tiger cat) for cat.jpg\n  size_t class_index = ArgMax\u0026lt;unsigned char\u0026gt;(output, 1001);\n\n  // 8. Clean up.\n  BandTensorDelete(input_tensor);\n  BandTensorDelete(output_tensor);\n\n  BandImageProcessorBuilderDelete(builder);\n  BandImageProcessorDelete(processor);\n  delete[] std::get\u0026lt;0\u0026gt;(image_buffer);\n\n  BandEngineDelete(engine);\n  BandConfigDelete(config);\n}\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"api-types\"\u003eAPI Types \u003ca href=\"#api-types\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eBand provides the following types in the C API:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eBandConfig\u003c/code\u003e: Configuration object for the engine.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBandConfigBuilder\u003c/code\u003e: Builder for the configuration object.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBandEngine\u003c/code\u003e: Engine object.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBandModel\u003c/code\u003e: Model object that holds the model data. \u003cem\u003eIt must outlive the engine.\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBandTensor\u003c/code\u003e: Tensor object that holds the input/output data of a model.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBandBuffer\u003c/code\u003e: Wrapper for any data buffer interchangable with \u003ccode\u003eBandTensor\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBandImageProcessor\u003c/code\u003e: Image processor object that converts an image buffer to a tensor.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBandImageProcessorBuilder\u003c/code\u003e: Builder for the image processor object.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBandRequestHandle\u003c/code\u003e: Handle for an asynchronous request.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"api-functions-engine\"\u003eAPI Functions (Engine) \u003ca href=\"#api-functions-engine\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"bandenginecreate\"\u003eBandEngineCreate \u003ca href=\"#bandenginecreate\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandEngine* BandEngineCreate(BandConfig* config);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCreates a BandEngine instance with the given configuration.\u003c/p\u003e\n\u003ch3 id=\"bandenginedelete\"\u003eBandEngineDelete \u003ca href=\"#bandenginedelete\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003evoid BandEngineDelete(BandEngine* engine);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDeletes the BandEngine instance.\u003c/p\u003e\n\u003ch3 id=\"bandengineregistermodel\"\u003eBandEngineRegisterModel \u003ca href=\"#bandengineregistermodel\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003evoid BandEngineRegisterModel(BandEngine* engine, BandModel* model);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRegisters a model to the engine. The engine will load the model and allocate resources for it.\u003c/p\u003e\n\u003ch3 id=\"bandengingegetnuminputtensors\"\u003eBandEngingeGetNumInputTensors \u003ca href=\"#bandengingegetnuminputtensors\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eint BandEngingeGetNumInputTensors(BandEngine* engine, BandModel* model);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eReturns the number of input tensors for the given model.\u003c/p\u003e\n\u003ch3 id=\"bandengingegetnumoutputtensors\"\u003eBandEngingeGetNumOutputTensors \u003ca href=\"#bandengingegetnumoutputtensors\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eint BandEngingeGetNumOutputTensors(BandEngine* engine, BandModel* model);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eReturns the number of output tensors for the given model.\u003c/p\u003e\n\u003ch3 id=\"bandenginegetnumworkers\"\u003eBandEngineGetNumWorkers \u003ca href=\"#bandenginegetnumworkers\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eint BandEngineGetNumWorkers(BandEngine* engine);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eReturns the number of workers in the engine.\u003c/p\u003e\n\u003ch3 id=\"bandenginegetworkerdevice\"\u003eBandEngineGetWorkerDevice \u003ca href=\"#bandenginegetworkerdevice\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandDeviceFlag BandEngineGetWorkerDevice(BandEngine* engine, int worker_index);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eReturns the device flag (e.g., \u003ccode\u003ekBandCPU\u003c/code\u003e, \u003ccode\u003ekBandGPU\u003c/code\u003e, \u0026hellip;) of the worker at the given index.\u003c/p\u003e\n\u003ch3 id=\"bandenginecreateinputtensor\"\u003eBandEngineCreateInputTensor \u003ca href=\"#bandenginecreateinputtensor\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandTensor* BandEngineCreateInputTensor(BandEngine* engine, BandModel* model,\n                                        int index);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCreates an input tensor for the given model. The tensor is allocated by the engine and must be deleted by the caller.\u003c/p\u003e\n\u003ch3 id=\"bandenginecreateoutputtensor\"\u003eBandEngineCreateOutputTensor \u003ca href=\"#bandenginecreateoutputtensor\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandTensor* BandEngineCreateOutputTensor(BandEngine* engine, BandModel* model,\n                                         int index);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCreates an output tensor for the given model. The tensor is allocated by the engine and must be deleted by the caller.\u003c/p\u003e\n\u003ch3 id=\"bandenginerequestsync\"\u003eBandEngineRequestSync \u003ca href=\"#bandenginerequestsync\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandStatus BandEngineRequestSync(\n    BandEngine* engine, BandModel* model, BandTensor** input_tensors,\n    BandTensor** output_tensors)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRuns the model with the given input tensors and stores the result in the output tensors. The function blocks until the execution is finished. Returns \u003ccode\u003ekBandOk\u003c/code\u003e if the execution is successful.\u003c/p\u003e\n\u003ch3 id=\"bandenginerequestasync\"\u003eBandEngineRequestAsync \u003ca href=\"#bandenginerequestasync\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandRequestHandle BandEngineRequestAsync(\n    BandEngine* engine, BandModel* model, BandTensor** input_tensors);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRuns the model with the given input tensors. The function returns immediately and the result will be stored in the output tensors when the execution is finished. Returns a handle to the request.\u003c/p\u003e\n\u003ch3 id=\"bandenginewait\"\u003eBandEngineWait \u003ca href=\"#bandenginewait\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandStatus BandEngineWait(BandEngine* engine, BandRequestHandle handle, \n    BandTensor** output_tensors, size_t num_outputs);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBlocks until the request is finished. Returns \u003ccode\u003ekBandOk\u003c/code\u003e if the execution is successful and the result is stored in the output tensors.\u003c/p\u003e\n\u003ch3 id=\"bandenginesetonendrequest\"\u003eBandEngineSetOnEndRequest \u003ca href=\"#bandenginesetonendrequest\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003evoid BandEngineSetOnEndRequest(\n    BandEngine* engine,\n    void (*on_end_invoke)(void* user_data, BandRequestHandle job_id, BandStatus status),\n    void* user_data);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSets a callback function that will be invoked when a request is finished. The callback function will be invoked in the engine thread. The \u003ccode\u003estatus\u003c/code\u003e is the status of the request.\u003c/p\u003e\n\u003ch2 id=\"api-functions-buffer\"\u003eAPI Functions (Buffer) \u003ca href=\"#api-functions-buffer\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eBand provides a buffer type that can be used to hold data for a tensor. The buffer can be created from a raw data pointer. The buffer can be converted to a tensor using an image processor.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eImageProcessorBuilder\u003c/code\u003e is used to build an \u003ccode\u003eImageProcessor\u003c/code\u003e. \u003ccode\u003eImageProcessor\u003c/code\u003e defines a series of operations to be applied to a \u003ccode\u003eBandBuffer\u003c/code\u003e and convert it to a \u003ccode\u003eBandTensor\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eBy default, builder without any operation will create a \u003ccode\u003eImageProcessor\u003c/code\u003e\nprovides a direct mapping from \u003ccode\u003eBandBuffer\u003c/code\u003e to \u003ccode\u003eBandTensor\u003c/code\u003e without normalization. E.g., automated color space conversion, resize to the output tensor shape, and data type conversion.\u003c/p\u003e\n\u003ch3 id=\"bandbuffercreate\"\u003eBandBufferCreate \u003ca href=\"#bandbuffercreate\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandBuffer* BandBufferCreate();\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCreates a buffer instance.\u003c/p\u003e\n\u003ch3 id=\"bandbufferdelete\"\u003eBandBufferDelete \u003ca href=\"#bandbufferdelete\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003evoid BandBufferDelete(BandBuffer* buffer);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDeletes the buffer instance.\u003c/p\u003e\n\u003ch3 id=\"bandbuffersetfromrawdata\"\u003eBandBufferSetFromRawData \u003ca href=\"#bandbuffersetfromrawdata\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandStatus BandBufferSetFromRawData(BandBuffer* buffer, const void* data,\n                                    size_t width, size_t height,\n                                    BandBufferFormat format);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSets the buffer from raw image data. Supported formats are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ekBandRGB\u003c/code\u003e (3 channels - 8 bits per channel, interleaved)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekBandRGBA\u003c/code\u003e (4 channels - 8 bits per channel, interleaved)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekBandGRAY\u003c/code\u003e (1 channel - 8 bits per channel)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekBandNV21\u003c/code\u003e (YUV 4:2:0 - 8 bits per channel, interleaved)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekBandNV12\u003c/code\u003e (YUV 4:2:0 - 8 bits per channel, interleaved)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekBandYV12\u003c/code\u003e (YUV 4:2:0 - 8 bits per channel, planar)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekBandYV21\u003c/code\u003e (YUV 4:2:0 - 8 bits per channel, planar)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"bandbuffersetfromyuvdata\"\u003eBandBufferSetFromYUVData \u003ca href=\"#bandbuffersetfromyuvdata\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandStatus BandBufferSetFromYUVData(BandBuffer* buffer, const void* y_data,\n                                    const void* u_data, const void* v_data,\n                                    size_t width, size_t height,\n                                    size_t row_stride_y, size_t row_stride_uv,\n                                    size_t pixel_stride_uv,\n                                    BandBufferFormat buffer_format);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSets the buffer from YUV data. Supported formats are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ekBandNV21\u003c/code\u003e (YUV 4:2:0 - 8 bits per channel, interleaved)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekBandNV12\u003c/code\u003e (YUV 4:2:0 - 8 bits per channel, interleaved)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekBandYV12\u003c/code\u003e (YUV 4:2:0 - 8 bits per channel, planar)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekBandYV21\u003c/code\u003e (YUV 4:2:0 - 8 bits per channel, planar)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"bandimageprocessorbuildercreate\"\u003eBandImageProcessorBuilderCreate \u003ca href=\"#bandimageprocessorbuildercreate\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandImageProcessorBuilder* BandImageProcessorBuilderCreate();\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCreates an image processor builder instance.\u003c/p\u003e\n\u003ch3 id=\"bandimageprocessorbuilderdelete\"\u003eBandImageProcessorBuilderDelete \u003ca href=\"#bandimageprocessorbuilderdelete\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003evoid BandImageProcessorBuilderDelete(BandImageProcessorBuilder* builder);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDeletes the image processor builder instance.\u003c/p\u003e\n\u003ch3 id=\"bandimageprocessorbuilderbuild\"\u003eBandImageProcessorBuilderBuild \u003ca href=\"#bandimageprocessorbuilderbuild\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandImageProcessor* BandImageProcessorBuilderBuild(\n    BandImageProcessorBuilder* builder);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBuilds an image processor instance from the builder.\u003c/p\u003e\n\u003ch3 id=\"bandaddoperator\"\u003eBandAddOperator \u003ca href=\"#bandaddoperator\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003e\nBandStatus BandAddOperator(BandImageProcessorBuilder* b,\n                           BandImageProcessorBuilderField field, int count, ...);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAdds an operator to the builder. The order of the operators will be the order of the operations applied to the input buffer. E.g., \u003ccode\u003eBandAddOperator(builder, BAND_IMAGE_PROCESSOR_CROP, 4, 0, 0, 100, 100);\u003c/code\u003e will crop the input buffer from (0, 0) to (100, 100). This will return \u003ccode\u003ekBandError\u003c/code\u003e if the given variadic arguments are invalid.\nAvailable operators are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eBAND_IMAGE_PROCESSOR_CROP\u003c/code\u003e: Crops the input buffer. \u003ccode\u003eint x0, int y0, int x1, int y1\u003c/code\u003e - crop from top-left corner, inclusive\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBAND_IMAGE_PROCESSOR_RESIZE\u003c/code\u003e: Resizes the input buffer. \u003ccode\u003eint width, int height\u003c/code\u003e - resize to a new size\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBAND_IMAGE_PROCESSOR_ROTATE\u003c/code\u003e: Rotates the input buffer. \u003ccode\u003efloat angle\u003c/code\u003e - counter-clockwise, between 0 and 360 in multiples of 90\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBAND_IMAGE_PROCESSOR_FLIP\u003c/code\u003e: Flips the input buffer. \u003ccode\u003ebool horizontal, bool vertical\u003c/code\u003e - flip horizontally and/or vertically\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBAND_IMAGE_PROCESSOR_CONVERT_COLOR_SPACE\u003c/code\u003e: Converts the color space of the input buffer. \u003ccode\u003eBandBufferFormat target_format\u003c/code\u003e - convert the color space\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBAND_IMAGE_PROCESSOR_NORMALIZE\u003c/code\u003e: Normalizes the input buffer. \u003ccode\u003efloat mean, float std\u003c/code\u003e - normalize the input buffer\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eBAND_IMAGE_PROCESSOR_DATA_TYPE_CONVERT\u003c/code\u003e: Converts the data type of the input buffer. No argument required Convert the data type to the output data type. E.g., convert from 8-bit RGB to 32-bit float RGB (tensor).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"bandimageprocessorprocess\"\u003eBandImageProcessorProcess \u003ca href=\"#bandimageprocessorprocess\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003eBandStatus BandImageProcessorProcess(BandImageProcessor* image_processor,\n                                     BandBuffer* buffer,\n                                     BandTensor* target_tensor);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eApplies the image processor to the input buffer and stores the result in the target tensor. Returns \u003ccode\u003ekBandOk\u003c/code\u003e if the operation is successful.\u003c/p\u003e\n\u003ch3 id=\"bandimageprocessordelete\"\u003eBandImageProcessorDelete \u003ca href=\"#bandimageprocessordelete\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003evoid BandImageProcessorDelete(BandImageProcessor* processor);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDeletes the image processor instance.\u003c/p\u003e\n"
      },
    {
        id: 9,
        href: "https://mrsnu.github.io/docs/api/unreal-plugin/",
        title: "Unreal Engine Plugin",
        description: "One page summary of how to use the Unreal Engine Plugin.",
        content: "\u003ch2 id=\"introduction\"\u003eIntroduction \u003ca href=\"#introduction\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eBand provides an official \u003ca href=\"https://github.com/mrsnu/band-ue\"\u003eplugin\u003c/a\u003e for Unreal Engine.\nWe support both \u003ccode\u003eBlueprint\u003c/code\u003e (visual scripting language of the UE) and C++ based interfaces.\u003c/p\u003e\n\u003ch2 id=\"example\"\u003eExample \u003ca href=\"#example\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWe first demonstrate how to use the plugin with a simple example.\nBelow code snippet is part of the \u003ccode\u003emobile augmented-reality classification\u003c/code\u003e example built with the C++ interface of the plugin.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"/example/\"\u003eLink to Example\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"c\"\u003eC++ \u003ca href=\"#c\" class=\"anchor\" aria-hidden=\"true\"\u003e#\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThe main workflow of the example is as follows:\nInitialize the plugin and load the model.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePreallocate the input and output tensors.\u003c/li\u003e\n\u003cli\u003eCreate a widget to display the camera image and the classification result.\u003c/li\u003e\n\u003cli\u003eStart the camera (we use our own camera \u003ca href=\"https://github.com/snuhcs/android-camera-ue\"\u003eplugin\u003c/a\u003e to access the Android camera).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003e// Called when the game starts or when spawned\nvoid ADetectionActor::BeginPlay() {\n  DetectorInputTensors = DetectorModel-\u0026gt;AllocateInputTensors();\n  DetectorOutputTensors = DetectorModel-\u0026gt;AllocateOutputTensors();\n\n  TSubclassOf\u0026lt;UBandUIBase\u0026gt; WidgetClassType = WidgetClass.LoadSynchronous();\n  Widget = CreateWidget\u0026lt;UBandUIBase\u0026gt;(GetWorld(), WidgetClassType);\n  Widget-\u0026gt;AddToViewport();\n\n  CameraImage = Cast\u0026lt;UImage\u0026gt;(Widget-\u0026gt;GetWidgetFromName(\u0026quot;CameraImage\u0026quot;));\n  GetGameInstance()-\u0026gt;GetSubsystem\u0026lt;UBandSubSystem\u0026gt;()-\u0026gt;OnEndInvoke.AddUObject(\n      this, \u0026amp;ADetectionActor::OnEndRequest);\n\n  AndroidCamera-\u0026gt;StartCamera(640, 640, 30);\n  AndroidCamera-\u0026gt;OnFrameAvailable.AddUObject(\n      this, \u0026amp;ADetectionActor::OnFrameAvailable);\n  AndroidCamera-\u0026gt;OnTextureAvailableDynamic.AddDynamic(\n      this, \u0026amp;ADetectionActor::OnTextureAvailable);\n\n  Super::BeginPlay();\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen a new frame is available, we feed the frame to the model and request the inference.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003evoid ADetectionActor::OnFrameAvailable(const UAndroidCameraFrame *Frame) {\n  DetectorInputTensors[0]-\u0026gt;FromCameraFrame(Frame, 0.f, 1.f);\n  FBandModule::Get().RequestAsync(DetectorModel, DetectorInputTensors);\n}\n\n\nvoid ADetectionActor::OnTextureAvailable(UTexture2D *Texture) {\n  CameraImage-\u0026gt;SetBrushFromTexture(Texture, true);\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen the inference is done, we get the result and update the widget.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003evoid ADetectionActor::OnEndRequest(int32 JobId, EBandStatus Status) {\n  if (Status == EBandStatus::Ok) {\n    UBandBlueprintLibrary::GetOutputs(JobId, DetectorOutputTensors);\n    TArray\u0026lt;FBandBoundingBox\u0026gt; BoundingBoxes =\n        UBandBlueprintLibrary::GetDetectedBoxes(\n            DetectorOutputTensors, EBandDetector::SSDMNetV2, Label);\n    Widget-\u0026gt;BoundingBoxes = BoundingBoxes;\n  } else {\n    UE_LOG(LogTemp, Error, TEXT(\u0026quot;Detection failed\u0026quot;));\n  }\n}\n\u003c/code\u003e\u003c/pre\u003e\n"
      },
    {
        id: 10,
        href: "https://mrsnu.github.io/docs/",
        title: "Docs",
        description: "Docs Doks.",
        content: ""
      },
    ];
  */

  // https://discourse.gohugo.io/t/range-length-or-last-element/3803/2

  

  index.add(
      {
        id: 0,
        href: "/docs/prologue/",
        title: "Prologue",
        description: "Prologue Doks.",
        content: ""
      }
    );
  index.add(
      {
        id: 1,
        href: "/docs/getting-started/",
        title: "Getting Started",
        description: "Getting Started",
        content: ""
      }
    );
  index.add(
      {
        id: 2,
        href: "/docs/api/",
        title: "API",
        description: "API",
        content: ""
      }
    );
  index.add(
      {
        id: 3,
        href: "/docs/prologue/introduction/",
        title: "Introduction",
        description: "Band is an efficient deep learning platform for mobile-cloud collaborative support for multiple DNNs. Band supports backend-agnostic coordination of DNN requests on heterogeneous processors in a mobile device to cloud server. Band is currently backed by following backend machine learning frameworks.\nTensorflow v2.9.2 \u0026hellip; Android â˜‘ iOS â˜ gRPC â˜ Band provides Java and C APIs, as well as an official plugin for Unreal Engine.\nQuick Start # ðŸ‘‰ The Quick Start is intended for intermediate to advanced users.",
        content: "Band is an efficient deep learning platform for mobile-cloud collaborative support for multiple DNNs. Band supports backend-agnostic coordination of DNN requests on heterogeneous processors in a mobile device to cloud server. Band is currently backed by following backend machine learning frameworks.\nTensorflow v2.9.2 \u0026hellip; Android â˜‘ iOS â˜ gRPC â˜ Band provides Java and C APIs, as well as an official plugin for Unreal Engine.\nQuick Start # ðŸ‘‰ The Quick Start is intended for intermediate to advanced users. One page summary of how to build and customize Band. Quick Start â†’\nExamples # See what others have build with Band. Example â†’\nAbout Us # Find out who we are. About Us-\u0026gt;\n"
      }
    );
  index.add(
      {
        id: 4,
        href: "/docs/getting-started/quick-start/",
        title: "Quick Start",
        description: "One page summary of how to use a Band.",
        content: "Prerequisites # Install Android SDK 28, NDK v19.2.53456\nor create Visual Studio Code Dev Container using [root]/.devcontainer or utilize [root]/.devcontainer/Dockerfile Install Bazel\nInstall Bazelisk or Bazel We recommend to use Bazelisk to avoid version mismatch Configure Android SDK, NDK for build system\npython configure.py How to build \u0026amp; run # Refer to detailed instructions in [root]/script\nRun test\npython script/run_test.py -android Build Android AAR\nsh script/build_aar_armv8.sh Build C API\npython script/build_c_api.py -android Run Benchmark\npython script/run_benchmark.py --config band/test/data/benchmark_config.json "
      }
    );
  index.add(
      {
        id: 5,
        href: "/docs/prologue/about-us/",
        title: "About Us",
        description: "Band is built and designed by the team `SNUMR` from Seoul National University Dept. of Computer Science and Engineering. We are cross-laboratory team from Software Platforms Lab and Human-Centered Computer-Systems Lab.",
        content: "Current Members # Youngki Lee, Byung-Gon Chun\nJingyu Lee, Changmin Jeon, Minjae Kim, Hyunsoo Kim, Seonjun Kim\nPrevious Members # Joo Seong Jeong, Donghyun Kim, Changjin Jeong\nCitation # If you find our work useful, please cite our paper below! The original codebase for paper submission is archived here\n@inproceedings{jeong2022band, title={Band: coordinated multi-DNN inference on heterogeneous mobile processors}, author={Jeong, Joo Seong and Lee, Jingyu and Kim, Donghyun and Jeon, Changmin and Jeong, Changjin and Lee, Youngki and Chun, Byung-Gon}, booktitle={Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services}, pages={235--247}, year={2022} } Acknowledgment # This work was supported by Samsung Research Funding \u0026amp; Incubation Center of Samsung Electronics under project number SRFC-IT2001-03.\n"
      }
    );
  index.add(
      {
        id: 6,
        href: "/docs/getting-started/benchmark/",
        title: "Benchmark Tool",
        description: "One page summary of how to use a Benchmark Tool for Band.",
        content: "Band provides a simple C++ binary to benchmark a runtime performance. The binary generates repeatitive model requests based on a given config file, and reports latency statistics afterwards.\nHow to run # [root]/script/run_benchmark.py script will build band_benchmark binary file and execute it with a specified config file. Built binary file and target config file can be found in [root]/benchmark.\nOn Android # If you want to build binary from docker container (Refer to [root]/script/docker_util.sh for more detail)\npython .\\script\\run_benchmark.py -android -docker -c .\\benchmark_config.json If you want to build locally\npython .\\script\\run_benchmark.py -android -c .\\benchmark_config.json On local desktop (Windows or Ubuntu) # python .\\script\\run_benchmark.py -c .\\benchmark_config.json Config file # Structure # models: Models to run. For each model, specify the following fields. graph: Model path. period_ms: Optional The delay between subsequent requests in ms. The argument is only effective with periodic execution mode. batch_size: The number of model requests in a frame. [default: 1] worker_id: Optional Specify the worker id to run in int. The argument is only effective with fixed_device scheduler. slo_us and slo_scale: Optional fields for specifying an SLO value for a model. Setting slo_scale will make the SLO = worst profiled latency of that model * slo_scale. slo_scale will be ignored if slo_us is given (i.e., no reason to specify both options). log_path: The log file path. (e.g., /data/local/tmp/model_execution_log.json) schedulers: The scheduler types in list[string]. If N schedulers are specified, then N queues are generated. fixed_worker round_robin shortest_expected_latency least_slack_time_first heterogeneous_earliest_finish_time heterogeneous_earliest_finish_time_reserved minimum_subgraph_size: Minimum subgraph size. If candidate subgraph size is smaller than minimum_subgraph_size, the subgraph will not be created. [default: 7] subgraph_preparation_type: For schedulers using fallback, determine how to generate candidate subgraphs. [default: merge_unit_subgraph] no_fallback_subgraph: Generate subgraphs per worker. Explicit fallback subgraph will not be generated. fallback_per_worker: Generate fallback subgraphs for each worker. unit_subgraph: Generate unit subgraphs considering all device supportiveness. All ops in same unit subgraph have same support devices. merge_unit_subgraph: Add merged unit subgraphs to unit_subgraph. execution_mode: Specify a exeucution mode. Available execution modes are as follows: stream: consecutively run batches. periodic: invoke requests periodically. workload: execute pre-defined sequence in stream manner based on a given workload file. cpu_masks: CPU cluster mask to set CPU affinity. [default: ALL] ALL: All Cluster LITTLE: LITTLE Cluster only BIG: Big Cluster only PRIMARY: Primary Core only num_threads: Number of computing threads for CPU delegates. [default: -1] planner_cpu_masks: CPU cluster mask to set CPU affinity of planner. [default: same value as global cpu_masks] workers: A vector-like config for per-processor worker. For each worker, specify the following fields. System creates 1 worker per device by default and first provided value overrides the settings (i.e., cpu_masks, num_threads, profile_copy_computation_ratio, \u0026hellip; ) and additional field will add additional worker per device. device: Target device of specific worker. CPU GPU DSP NPU cpu_masks: CPU cluster mask to set CPU affinity of specific worker. [default: same value as global cpu_masks] num_threads: Number of threads. [default: same value as global num_threads] running_time_ms: Experiment duration in ms. [default: 60000] profile_smoothing_factor: Current profile reflection ratio. updated_profile = profile_smoothing_factor * curr_profile + (1 - profile_smoothing_factor) * prev_profile [default: 0.1] model_profile: The path to file with model profile results. [default: None] profile_online: Online profile or offline profile [default: true] profile_warmup_runs: Number of warmup runs before profile. [default: 1] profile_num_runs: Number of runs for profile. [default: 1] profile_copy_computation_ratio: Ratio of computation / input-ouput copy in list[int]. Used for latency estimation for each device type (e.g., CPU, GPU, DSP, NPU). The length of the list should be equal to the 4 (GetSize\u0026lt;DeviceFlags\u0026gt;()). [default: 30000, 30000, 30000, 30000] schedule_window_size: The number of planning unit. workload: The path to file with workload information. [default: None] Example # { \u0026quot;models\u0026quot;: [ { \u0026quot;graph\u0026quot;: \u0026quot;/data/local/tmp/model/lite-model_efficientdet_lite0_int8_1.tflite\u0026quot;, \u0026quot;period_ms\u0026quot;: 30, \u0026quot;batch_size\u0026quot;: 3 }, { \u0026quot;graph\u0026quot;: \u0026quot;/data/local/tmp/model/retinaface_mbv2_quant_160.tflite\u0026quot;, \u0026quot;period_ms\u0026quot;: 30, \u0026quot;batch_size\u0026quot;: 3 }, { \u0026quot;graph\u0026quot;: \u0026quot;/data/local/tmp/model/ssd_mobilenet_v1_1_metadata_1.tflite\u0026quot;, \u0026quot;period_ms\u0026quot;: 30, \u0026quot;batch_size\u0026quot;: 3 } ], \u0026quot;log_path\u0026quot;: \u0026quot;/data/local/tmp/log.json\u0026quot;, \u0026quot;schedulers\u0026quot;: [ \u0026quot;heterogeneous_earliest_finish_time_reserved\u0026quot; ], \u0026quot;minimum_subgraph_size\u0026quot;: 7, \u0026quot;subgraph_preparation_type\u0026quot;: \u0026quot;merge_unit_subgraph\u0026quot;, \u0026quot;execution_mode\u0026quot;: \u0026quot;stream\u0026quot;, \u0026quot;cpu_masks\u0026quot;: \u0026quot;ALL\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;planner_cpu_masks\u0026quot;: \u0026quot;PRIMARY\u0026quot;, \u0026quot;workers\u0026quot;: [ { \u0026quot;device\u0026quot;: \u0026quot;CPU\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;cpu_masks\u0026quot;: \u0026quot;BIG\u0026quot; }, { \u0026quot;device\u0026quot;: \u0026quot;CPU\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;cpu_masks\u0026quot;: \u0026quot;LITTLE\u0026quot; }, { \u0026quot;device\u0026quot;: \u0026quot;GPU\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;cpu_masks\u0026quot;: \u0026quot;ALL\u0026quot; }, { \u0026quot;device\u0026quot;: \u0026quot;DSP\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;cpu_masks\u0026quot;: \u0026quot;PRIMARY\u0026quot; }, { \u0026quot;device\u0026quot;: \u0026quot;NPU\u0026quot;, \u0026quot;num_threads\u0026quot;: 1, \u0026quot;cpu_masks\u0026quot;: \u0026quot;PRIMARY\u0026quot; } ], \u0026quot;running_time_ms\u0026quot;: 10000, \u0026quot;profile_smoothing_factor\u0026quot;: 0.1, \u0026quot;profile_data_path\u0026quot;: \u0026quot;/data/local/tmp/profile.json\u0026quot;, \u0026quot;profile_online\u0026quot;: true, \u0026quot;profile_warmup_runs\u0026quot;: 3, \u0026quot;profile_num_runs\u0026quot;: 50, \u0026quot;profile_copy_computation_ratio\u0026quot;: [ 1000, 1000, 1000, 1000 ], \u0026quot;availability_check_interval_ms\u0026quot;: 30000, \u0026quot;schedule_window_size\u0026quot;: 10 } "
      }
    );
  index.add(
      {
        id: 7,
        href: "/docs/getting-started/config/",
        title: "Config",
        description: "Configuration and its Builder for Band Runtime.",
        content: "There are four configuration objects for each Band\u0026rsquo;s component.\nEach configuration field is optional or required. If a field is optional, then it is guaranteed that the default value exists. If a field is required, a configuration cannot be generated by RuntimeConfigBuilder without specifying the field.\nEnumeration Types # SchedulerType\nkBandFixedDeviceFixedWorker SchedulerType::RoundRobin SchedulerType::ShortestExpectedLatency kBandFixedDeviceFixedWorkerGlobalQueue SchedulerType::HeterogeneousEarliestFinishTime SchedulerType::LeastSlackTimeFirst SchedulerType::HeterogeneousEarliestFinishTimeReserved CPUMaskFlags\nCPUMaskFlags::All CPUMaskFlags::Little CPUMaskFlags::Big CPUMaskFlags::Primary DeviceFlags\nDeviceFlags::CPU DeviceFlags::GPU DeviceFlags::DSP DeviceFlags::NPU SubgraphPreparationType\nSubgraphPreparationType::NoFallbackSubgraph SubgraphPreparationType::FallbackPerWorker SubgraphPreparationType::UnitSubgraph SubgraphPreparationType::MergeUnitSubgraph ProfileConfig # online [type: bool, default: true]: Profile online if true, offline if false. num_warmups [type: int, default: 1]: The number of warmup runs before profile. num_runs [type: int, default: 1]: The number of runs for profile copy_computation_ratio [type: std::vector\u0026lt;int\u0026gt;, default: [30000, ...]]: The ratio of computation to input-output copy. Used for latency estimation. The size of the list should be the same as the number of devices. smoothing_factor [type: float, default: 0.1]: The momentum to reflect current profiled data. \u0026lt;updateed_profile\u0026gt; = \u0026lt;smoothing_factor\u0026gt; * \u0026lt;curr_profile\u0026gt; + (1. - \u0026lt;smoothing_factor\u0026gt;) * \u0026lt;prev_profile\u0026gt;. profile_data_path [type: std::string, default: \u0026quot;\u0026quot;]: The input path to the file for offline profile results. If not specified, this will be ignored and will not generate the result file. PlannerConfig # schedule_window_size [type: int, default: INT_MAX]: The size of window that scheduler will use. schedulers [type: std::vector\u0026lt;SchedulerType\u0026gt;, required]: The types of schedulers. If N schedulers are specified, N queues will be generated. cpu_mask [type: CPUMaskFlags, default: CPUMaskFlags::All]: CPU masks to set CPU affinity. log_path [type: std::string, default: \u0026quot;\u0026quot;]: The output path to the file for planner\u0026rsquo;s log. If not specified, this will be ignored and will not generate the result file. WorkerConfig # workers [type: std::vector\u0026lt;DeviceFlags\u0026gt;, default: [DeviceFlags::CPU, DeviceFlags::GPU, ...]]: The list of target devices. By default, one worker per device is generated. cpu_masks [type: std::vector\u0026lt;CPUMaskFlags\u0026gt;, default: [CPUMaskFlags::All, CPUMaskFlags::All, ...]]: CPU masks to set CPU affinity. The size of the list must be the same as the size of workers. num_threads [type: std::vector\u0026lt;int\u0026gt;, default: [1, 1, ...]]: The number of threads. The size of the list must be the same as the size of workers. allow_worksteal [type: bool, default: false]: Work-stealing is enabled if true, disabled if false. availability_check_interval_ms [type: int, default: 30_000]: The interval for checking availability of devices. Used for detecting thermal throttling. RuntimeConfig # RuntimeConfig contains ProfileConfig, PlannerConfig and WorkerConfig. minimum_subgraph_size [type: int, default: 7]: The minimum subgraph size. If candidate subgraph size is smaller than this, the subgraph will not be created. subgraph_preparation_type [type: SubgraphPreparationType, default: SubgraphPreparationType::MergeUnitSubgraph]: For fallback schedulers, determine how to generate candidate subgraphs. cpu_mask [type: CPUMaskFlags, default: CPUMaskFlags::All]: The CPU mask for Band Engine. RuntimeConfigBuilder API # RuntimeConfigBuilder delegates all builder that inherits ConfigBuilder. It is a friend class of all the other ConfigBuilder classes, so make sure to not change their members in RuntimeConfigBuilder.\nExmaple Usage # RuntimeConfigBuilder b; auto config = b.AddOnline(false) // Default was `true` .AddSmoothingFactor(0.3) // Default was `0.1` .AddSchedulers({SchedulerType::RoundRobin, SchedulerType::LeastSlackTimeFirst}) // Required field. .Build(); Methods # All Add* methods are idempotent, i.e. multiple calls behaves the same as a single call.\nAddOnline(bool online) AddNumWarmups(int num_warmups) AddNumRuns(int num_runs) AddCopyComputationRatio(std::vector\u0026lt;int\u0026gt; copy_computation_ratio) AddSmoothingFactor(float smoothing_factor) AddProfileLogPath(std::string profile_data_path) AddPlannerLogPath(std::string planner_log_path) AddScheduleWindowSize(int schedule_window_size) AddSchedulers(std::vector\u0026lt;SchedulerType\u0026gt; schedulers) AddPlannerCPUMask(CPUMaskFlags cpu_masks) AddWorkers(std::vector\u0026lt;DeviceFlags\u0026gt; workers) AddWorkerCPUMasks(std::vector\u0026lt;CPUMaskFlags\u0026gt; cpu_masks) AddWorkerNumThreads(std::vector\u0026lt;int\u0026gt; num_threads) AddAllowWorkSteal(bool allow_worksteal) AddAvailabilityCheckIntervalMs(int32_t availability_check_interval_ms) AddMinimumSubgraphSize(int minimum_subgraph_size) AddSubgraphPreparationType(SubgraphPreparationType subgraph_preparation_type) AddCPUMask(CPUMaskFlags cpu_mask) "
      }
    );
  index.add(
      {
        id: 8,
        href: "/docs/api/c/",
        title: "C",
        description: "One page summary of how to use a C API.",
        content: "Introduction # Band provides a C API for developers who want to use Band in their C/C++ projects. The API is a thin wrapper around the core C++ API. The C API is available in the libband.h header file.\nLink provides a complete example of how to dynamically load the library and use the C API.\nExample # #include \u0026lt;libband.h\u0026gt; int main() { // 1. Create a configuration for the engine. BandConfigBuilder* b = BandConfigBuilderCreate(); BandAddConfig(b, BAND_PLANNER_LOG_PATH, /*count=*/1, \u0026quot;log.json\u0026quot;); BandAddConfig(b, BAND_PLANNER_SCHEDULERS, /*count=*/1, kBandHeterogeneousEarliestFinishTime); BandConfig* config = BandConfigCreate(b); // 2. Create an engine. BandEngine* engine = BandEngineCreate(config); // 3. Create and register a model. BandModel* model = BandModelCreate(); BandModelAddFromFile(model, kBandTfLite, \u0026quot;mobilenet_v2_1.0_224_quant.tflite\u0026quot;); BandEngineRegisterModel(engine, model); // 4. Create input and output tensors for the model. BandTensor* input_tensor = BandEngineCreateInputTensor(engine, model, 0); BandTensor* output_tensor = BandEngineCreateOutputTensor(engine, model, 0); std::tuple\u0026lt;unsigned char*, int, int\u0026gt; image_buffer = LoadRGBImageRaw(\u0026quot;cat.jpg\u0026quot;); // 5. (Optional) Create a buffer and an image processor to initialize the // input tensor with the image data. BandBuffer* buffer = BandBufferCreate(); BandBufferSetFromRawData(buffer, std::get\u0026lt;0\u0026gt;(image_buffer), std::get\u0026lt;1\u0026gt;(image_buffer), std::get\u0026lt;2\u0026gt;(image_buffer), kBandRGB); BandImageProcessorBuilder* builder = BandImageProcessorBuilderCreate(); BandImageProcessor* processor = BandImageProcessorBuilderBuild(builder); BandImageProcessorProcess(processor, buffer, input_tensor); // 6. Run the model. BandEngineRequestSync(engine, model, \u0026amp;input_tensor, \u0026amp;output_tensor); // 7. Get the result (class index). unsigned char* output = static_cast\u0026lt;unsigned char*\u0026gt;(BandTensorGetData(output_tensor)); // should be 282 (tiger cat) for cat.jpg size_t class_index = ArgMax\u0026lt;unsigned char\u0026gt;(output, 1001); // 8. Clean up. BandTensorDelete(input_tensor); BandTensorDelete(output_tensor); BandImageProcessorBuilderDelete(builder); BandImageProcessorDelete(processor); delete[] std::get\u0026lt;0\u0026gt;(image_buffer); BandEngineDelete(engine); BandConfigDelete(config); } API Types # Band provides the following types in the C API:\nBandConfig: Configuration object for the engine. BandConfigBuilder: Builder for the configuration object. BandEngine: Engine object. BandModel: Model object that holds the model data. It must outlive the engine. BandTensor: Tensor object that holds the input/output data of a model. BandBuffer: Wrapper for any data buffer interchangable with BandTensor. BandImageProcessor: Image processor object that converts an image buffer to a tensor. BandImageProcessorBuilder: Builder for the image processor object. BandRequestHandle: Handle for an asynchronous request. API Functions (Engine) # BandEngineCreate # BandEngine* BandEngineCreate(BandConfig* config); Creates a BandEngine instance with the given configuration.\nBandEngineDelete # void BandEngineDelete(BandEngine* engine); Deletes the BandEngine instance.\nBandEngineRegisterModel # void BandEngineRegisterModel(BandEngine* engine, BandModel* model); Registers a model to the engine. The engine will load the model and allocate resources for it.\nBandEngingeGetNumInputTensors # int BandEngingeGetNumInputTensors(BandEngine* engine, BandModel* model); Returns the number of input tensors for the given model.\nBandEngingeGetNumOutputTensors # int BandEngingeGetNumOutputTensors(BandEngine* engine, BandModel* model); Returns the number of output tensors for the given model.\nBandEngineGetNumWorkers # int BandEngineGetNumWorkers(BandEngine* engine); Returns the number of workers in the engine.\nBandEngineGetWorkerDevice # BandDeviceFlag BandEngineGetWorkerDevice(BandEngine* engine, int worker_index); Returns the device flag (e.g., kBandCPU, kBandGPU, \u0026hellip;) of the worker at the given index.\nBandEngineCreateInputTensor # BandTensor* BandEngineCreateInputTensor(BandEngine* engine, BandModel* model, int index); Creates an input tensor for the given model. The tensor is allocated by the engine and must be deleted by the caller.\nBandEngineCreateOutputTensor # BandTensor* BandEngineCreateOutputTensor(BandEngine* engine, BandModel* model, int index); Creates an output tensor for the given model. The tensor is allocated by the engine and must be deleted by the caller.\nBandEngineRequestSync # BandStatus BandEngineRequestSync( BandEngine* engine, BandModel* model, BandTensor** input_tensors, BandTensor** output_tensors) Runs the model with the given input tensors and stores the result in the output tensors. The function blocks until the execution is finished. Returns kBandOk if the execution is successful.\nBandEngineRequestAsync # BandRequestHandle BandEngineRequestAsync( BandEngine* engine, BandModel* model, BandTensor** input_tensors); Runs the model with the given input tensors. The function returns immediately and the result will be stored in the output tensors when the execution is finished. Returns a handle to the request.\nBandEngineWait # BandStatus BandEngineWait(BandEngine* engine, BandRequestHandle handle, BandTensor** output_tensors, size_t num_outputs); Blocks until the request is finished. Returns kBandOk if the execution is successful and the result is stored in the output tensors.\nBandEngineSetOnEndRequest # void BandEngineSetOnEndRequest( BandEngine* engine, void (*on_end_invoke)(void* user_data, BandRequestHandle job_id, BandStatus status), void* user_data); Sets a callback function that will be invoked when a request is finished. The callback function will be invoked in the engine thread. The status is the status of the request.\nAPI Functions (Buffer) # Band provides a buffer type that can be used to hold data for a tensor. The buffer can be created from a raw data pointer. The buffer can be converted to a tensor using an image processor.\nImageProcessorBuilder is used to build an ImageProcessor. ImageProcessor defines a series of operations to be applied to a BandBuffer and convert it to a BandTensor.\nBy default, builder without any operation will create a ImageProcessor provides a direct mapping from BandBuffer to BandTensor without normalization. E.g., automated color space conversion, resize to the output tensor shape, and data type conversion.\nBandBufferCreate # BandBuffer* BandBufferCreate(); Creates a buffer instance.\nBandBufferDelete # void BandBufferDelete(BandBuffer* buffer); Deletes the buffer instance.\nBandBufferSetFromRawData # BandStatus BandBufferSetFromRawData(BandBuffer* buffer, const void* data, size_t width, size_t height, BandBufferFormat format); Sets the buffer from raw image data. Supported formats are:\nkBandRGB (3 channels - 8 bits per channel, interleaved) kBandRGBA (4 channels - 8 bits per channel, interleaved) kBandGRAY (1 channel - 8 bits per channel) kBandNV21 (YUV 4:2:0 - 8 bits per channel, interleaved) kBandNV12 (YUV 4:2:0 - 8 bits per channel, interleaved) kBandYV12 (YUV 4:2:0 - 8 bits per channel, planar) kBandYV21 (YUV 4:2:0 - 8 bits per channel, planar) BandBufferSetFromYUVData # BandStatus BandBufferSetFromYUVData(BandBuffer* buffer, const void* y_data, const void* u_data, const void* v_data, size_t width, size_t height, size_t row_stride_y, size_t row_stride_uv, size_t pixel_stride_uv, BandBufferFormat buffer_format); Sets the buffer from YUV data. Supported formats are:\nkBandNV21 (YUV 4:2:0 - 8 bits per channel, interleaved) kBandNV12 (YUV 4:2:0 - 8 bits per channel, interleaved) kBandYV12 (YUV 4:2:0 - 8 bits per channel, planar) kBandYV21 (YUV 4:2:0 - 8 bits per channel, planar) BandImageProcessorBuilderCreate # BandImageProcessorBuilder* BandImageProcessorBuilderCreate(); Creates an image processor builder instance.\nBandImageProcessorBuilderDelete # void BandImageProcessorBuilderDelete(BandImageProcessorBuilder* builder); Deletes the image processor builder instance.\nBandImageProcessorBuilderBuild # BandImageProcessor* BandImageProcessorBuilderBuild( BandImageProcessorBuilder* builder); Builds an image processor instance from the builder.\nBandAddOperator # BandStatus BandAddOperator(BandImageProcessorBuilder* b, BandImageProcessorBuilderField field, int count, ...); Adds an operator to the builder. The order of the operators will be the order of the operations applied to the input buffer. E.g., BandAddOperator(builder, BAND_IMAGE_PROCESSOR_CROP, 4, 0, 0, 100, 100); will crop the input buffer from (0, 0) to (100, 100). This will return kBandError if the given variadic arguments are invalid. Available operators are:\nBAND_IMAGE_PROCESSOR_CROP: Crops the input buffer. int x0, int y0, int x1, int y1 - crop from top-left corner, inclusive BAND_IMAGE_PROCESSOR_RESIZE: Resizes the input buffer. int width, int height - resize to a new size BAND_IMAGE_PROCESSOR_ROTATE: Rotates the input buffer. float angle - counter-clockwise, between 0 and 360 in multiples of 90 BAND_IMAGE_PROCESSOR_FLIP: Flips the input buffer. bool horizontal, bool vertical - flip horizontally and/or vertically BAND_IMAGE_PROCESSOR_CONVERT_COLOR_SPACE: Converts the color space of the input buffer. BandBufferFormat target_format - convert the color space BAND_IMAGE_PROCESSOR_NORMALIZE: Normalizes the input buffer. float mean, float std - normalize the input buffer BAND_IMAGE_PROCESSOR_DATA_TYPE_CONVERT: Converts the data type of the input buffer. No argument required Convert the data type to the output data type. E.g., convert from 8-bit RGB to 32-bit float RGB (tensor). BandImageProcessorProcess # BandStatus BandImageProcessorProcess(BandImageProcessor* image_processor, BandBuffer* buffer, BandTensor* target_tensor); Applies the image processor to the input buffer and stores the result in the target tensor. Returns kBandOk if the operation is successful.\nBandImageProcessorDelete # void BandImageProcessorDelete(BandImageProcessor* processor); Deletes the image processor instance.\n"
      }
    );
  index.add(
      {
        id: 9,
        href: "/docs/api/unreal-plugin/",
        title: "Unreal Engine Plugin",
        description: "One page summary of how to use the Unreal Engine Plugin.",
        content: "Introduction # Band provides an official plugin for Unreal Engine. We support both Blueprint (visual scripting language of the UE) and C++ based interfaces.\nExample # We first demonstrate how to use the plugin with a simple example. Below code snippet is part of the mobile augmented-reality classification example built with the C++ interface of the plugin.\nLink to Example\nC++ # The main workflow of the example is as follows: Initialize the plugin and load the model.\nPreallocate the input and output tensors. Create a widget to display the camera image and the classification result. Start the camera (we use our own camera plugin to access the Android camera). // Called when the game starts or when spawned void ADetectionActor::BeginPlay() { DetectorInputTensors = DetectorModel-\u0026gt;AllocateInputTensors(); DetectorOutputTensors = DetectorModel-\u0026gt;AllocateOutputTensors(); TSubclassOf\u0026lt;UBandUIBase\u0026gt; WidgetClassType = WidgetClass.LoadSynchronous(); Widget = CreateWidget\u0026lt;UBandUIBase\u0026gt;(GetWorld(), WidgetClassType); Widget-\u0026gt;AddToViewport(); CameraImage = Cast\u0026lt;UImage\u0026gt;(Widget-\u0026gt;GetWidgetFromName(\u0026quot;CameraImage\u0026quot;)); GetGameInstance()-\u0026gt;GetSubsystem\u0026lt;UBandSubSystem\u0026gt;()-\u0026gt;OnEndInvoke.AddUObject( this, \u0026amp;ADetectionActor::OnEndRequest); AndroidCamera-\u0026gt;StartCamera(640, 640, 30); AndroidCamera-\u0026gt;OnFrameAvailable.AddUObject( this, \u0026amp;ADetectionActor::OnFrameAvailable); AndroidCamera-\u0026gt;OnTextureAvailableDynamic.AddDynamic( this, \u0026amp;ADetectionActor::OnTextureAvailable); Super::BeginPlay(); } When a new frame is available, we feed the frame to the model and request the inference.\nvoid ADetectionActor::OnFrameAvailable(const UAndroidCameraFrame *Frame) { DetectorInputTensors[0]-\u0026gt;FromCameraFrame(Frame, 0.f, 1.f); FBandModule::Get().RequestAsync(DetectorModel, DetectorInputTensors); } void ADetectionActor::OnTextureAvailable(UTexture2D *Texture) { CameraImage-\u0026gt;SetBrushFromTexture(Texture, true); } When the inference is done, we get the result and update the widget.\nvoid ADetectionActor::OnEndRequest(int32 JobId, EBandStatus Status) { if (Status == EBandStatus::Ok) { UBandBlueprintLibrary::GetOutputs(JobId, DetectorOutputTensors); TArray\u0026lt;FBandBoundingBox\u0026gt; BoundingBoxes = UBandBlueprintLibrary::GetDetectedBoxes( DetectorOutputTensors, EBandDetector::SSDMNetV2, Label); Widget-\u0026gt;BoundingBoxes = BoundingBoxes; } else { UE_LOG(LogTemp, Error, TEXT(\u0026quot;Detection failed\u0026quot;)); } } "
      }
    );
  index.add(
      {
        id: 10,
        href: "/docs/",
        title: "Docs",
        description: "Docs Doks.",
        content: ""
      }
    );
  search.addEventListener('input', show_results, true);

  function show_results(){
    const maxResult = 5;
    var searchQuery = this.value;
    var results = index.search(searchQuery, {limit: maxResult, enrich: true});

    // flatten results since index.search() returns results for each indexed field
    const flatResults = new Map(); // keyed by href to dedupe results
    for (const result of results.flatMap(r => r.result)) {
      if (flatResults.has(result.doc.href)) continue;
      flatResults.set(result.doc.href, result.doc);
    }

    suggestions.innerHTML = "";
    suggestions.classList.remove('d-none');

    // inform user that no results were found
    if (flatResults.size === 0 && searchQuery) {
      const noResultsMessage = document.createElement('div')
      noResultsMessage.innerHTML = `No results for "<strong>${searchQuery}</strong>"`
      noResultsMessage.classList.add("suggestion__no-results");
      suggestions.appendChild(noResultsMessage);
      return;
    }

    // construct a list of suggestions
    for(const [href, doc] of flatResults) {
        const entry = document.createElement('div');
        suggestions.appendChild(entry);

        const a = document.createElement('a');
        a.href = href;
        entry.appendChild(a);

        const title = document.createElement('span');
        title.textContent = doc.title;
        title.classList.add("suggestion__title");
        a.appendChild(title);

        const description = document.createElement('span');
        description.textContent = doc.description;
        description.classList.add("suggestion__description");
        a.appendChild(description);

        suggestions.appendChild(entry);

        if(suggestions.childElementCount == maxResult) break;
    }
  }
}());
